{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Toolbox txt files to Common Separated Values (csv) files for Conversation Analysis\n",
    "This code was written by Sarah Moeller, University of Colorado Boulder on February 7, 2020. sarah.moeller@colorado.edu. \n",
    "\n",
    "This code was originally made for Irina Wagner who needed to quickly convert Arapaho data in order to conduct conversation analysis for her dissertation.\n",
    "\n",
    "_Instructions to run code at bottom of file._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpaces(toolboxline):\n",
    "    # multiple spaces -> one space\n",
    "    # spacehyphen >> hyphen\n",
    "    # hyphenspace -> hyphen\n",
    "    \n",
    "    toolboxline = toolboxline.replace(',', ' ')\n",
    "    toolboxline = ' '.join(toolboxline.split())\n",
    "    toolboxline = toolboxline.replace(' -', '-')\n",
    "    toolboxline = toolboxline.replace('- ', '-')\n",
    "    \n",
    "    return toolboxline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolbox2CA(filename):\n",
    "    '''Reformats Irina's toolbox txt files.\n",
    "    Writes to csv file'''\n",
    "    \n",
    "    NEWFILE = filename.split('.')[0] + '.csv'\n",
    "    newlines = ''\n",
    "    newline = ''\n",
    "    anonymized = {'1': 'Margaret', '2': 'Joy', '3': 'Robert', '4': 'Sandra', '5': 'Bill', \n",
    "                  '6': 'John', '7': 'David', '8': 'Barb', '10': 'Mark', '11': 'Carol', '12': \n",
    "                  'Judy', '13': 'Betty', '14': 'Nancy', '15': 'Sharon', '16': 'Philip', \n",
    "                  '17': 'Linda', '18': 'Sam', '19': 'Timothy', '20': 'Martha', '21': 'Patricia', \n",
    "                  '22': 'Kathy', '23': 'Shirley', '24': 'Karen', '25': 'Phyllis', '26': 'Joyce', \n",
    "                  '27': 'Ann', '28': 'Albert', '29': 'Gloria', '30': 'Michael', '31': 'Alice', \n",
    "                  '32': 'Dennis', '33': 'Joe', '34': 'Ray', '35': 'Gary', '36': 'Steve', \n",
    "                  '37': 'Donna', '38': 'Virginia', '39': 'Doris', '40': 'Richard', '41': 'Elaine',\n",
    "                  '42': 'Bonny', '44': 'Carla', '45': 'Larry', '46': 'Dan', '47': 'Peter', \n",
    "                  '48': 'Ronny', '49': 'George', '50': 'Donald', '51': 'Jerry', '52': 'Tom', \n",
    "                  '53': 'Sue', '54': 'Bruce', '55': 'Douglas', '56': 'Terry', '57': 'Roger', \n",
    "                  '58': 'Debbie', '59': 'Henry', '60': 'Frank', '61': 'Carla', '62': 'Researcher',\n",
    "                  '63': 'Arthur', '64': 'Brenda', '65': 'Walter', '66': 'Willie', '67': 'Greg', \n",
    "                  '68': 'Marilyn', '69': 'Glenn', '70': 'Janice', '71': 'Peggy', '72': 'Fred', \n",
    "                  '73': 'Helen', 'XXX':'unknown', 'noid':'unknown'}\n",
    "    \n",
    "    inF = open(filename)\n",
    "    lines = inF.readlines()\n",
    "    inF.close()\n",
    "    \n",
    "    for line in lines[3:]:\n",
    "        line = removeSpaces(line)\n",
    "        # get the turn ID\n",
    "        if line.startswith('ref'):\n",
    "            linesplit = line.strip().split('.')\n",
    "            newline = linesplit[-1] + ','\n",
    "        # get name ID and original sentence\n",
    "        elif line.startswith('tx@'):\n",
    "            nameID = line.split()[0].split('@')[1]\n",
    "            orgSent = ','.join(line.split()[1:])\n",
    "            newline += anonymized[nameID] \n",
    "            newline += ':,' + orgSent + '\\n'\n",
    "        # get glosses, separated by comma\n",
    "        elif line.startswith('ge@') or line.startswith('mb@') or line.startswith('ps@'):\n",
    "            items = ','.join(line.split()[1:])\n",
    "            newline += ',,' + items + '\\n'\n",
    "        # get free translation\n",
    "        elif line.startswith('ft@'):\n",
    "            newline += ',,' + ' '.join(line.split()[1:]) + '\\n'\n",
    "        # get silence ID\n",
    "        elif line.startswith('SD'):\n",
    "            newline += ',,' + ''.join(line.split()[-1]) + '\\n'\n",
    "        # new line between turns\n",
    "        else:\n",
    "            newline += '\\n'\n",
    "            newlines += newline\n",
    "            newline = ''\n",
    "    with open(NEWFILE, 'w') as NF:\n",
    "        NF.write(newlines)\n",
    "    #return newlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Run Code\n",
    "1) Change path to directory if files are in different directory than this code file. Change replacing ./ with the path to new directory. If the files are in the same folder as this code file, use directory = r'./'.\n",
    "\n",
    "2) Make sure all files that need converting have the extension: .txt.\n",
    "\n",
    "3) Run code below. It will print out the name of all files that it didn't convert to csv. The CSV files will be saved in same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./.ipynb_checkpoints\n",
      "./54d-trans.csv\n",
      "./63c interlinear.csv\n",
      "./Arapaho_all_txt\n",
      "./Arapaho_all_xml\n",
      "./arp-Inflections.xlsx\n",
      "./arp-phonology1.jpg\n",
      "./arp-phonology2.jpg\n",
      "./arp-phonology3.jpg\n",
      "./arp-phonology4.jpg\n",
      "./arp-phonology5.jpg\n",
      "./arp-phonology6.jpg\n",
      "./caFormat.ipynb\n",
      "./ddo-all-txts-examples.csv\n",
      "./FLExbackupofLezgi(QusarQubaDialect)project2019-1-310.ramp\n",
      "./FormattingNotes.docx\n",
      "./lez-all_txts.flextext\n",
      "./lez-poems.flextext\n",
      "./Lezgi-Qusar dialect 2014-03-21 1202 AfterThesisWork-SomeCorrectionsToVar....fwbackup\n",
      "./Lezgi-Qusar dialect 2019-12-12 0934 change_comps.fwbackup\n",
      "./mni-all_txts.flextext\n",
      "./mni_HLTextCollection2011 2012-07-12 1440.fwbackup\n",
      "./Natqgu 2019-03-02 0213.fwbackup\n",
      "./Natqgu-Automated_Morph_Analysis 2019-12-12 0938 change_comps.fwbackup\n",
      "./Natugu_IGT-4MT.flextext\n",
      "./ntu-all_txts.flextext\n",
      "./PreprocessArapaho-MorphGloss.ipynb\n",
      "./Toolbox POS.docx\n",
      "./~$rmattingNotes.docx\n"
     ]
    }
   ],
   "source": [
    "directory = r'./'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        toolbox2CA(filename)\n",
    "    else:\n",
    "        print(os.path.join(directory, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
